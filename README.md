ä¸‹é¢æ˜¯ **å®Œæ•´ã€å¯ç›´æ¥å¤åˆ¶ã€ä¸ä¼šè¢« Markdown ç ´åæ ¼å¼çš„ `README.md`**ã€‚
ä½ å¯ä»¥æŠŠå®ƒç›´æ¥æ”¾å…¥é¡¹ç›®æ ¹ç›®å½•ï¼ŒGitHub ä¸Šæ˜¾ç¤ºæ•ˆæœéå¸¸ä¸“ä¸šã€‚

---

# ğŸ¯ **å®Œæ•´å¯å¤åˆ¶ç‰ˆ README.mdï¼ˆæœ€ç»ˆç‰ˆï¼‰**

```markdown
# NBA Play-by-Play Streaming Pipeline  
### Kafka + ChromaDB + Real-Time Retrieval + Analyst CLI

This project implements a **real-time streaming and retrieval pipeline** for NBA play-by-play data using:

- **Apache Kafka** (streaming)
- **Python producers/consumers**
- **ChromaDB** (vector search)
- **Hashing embeddings** (fast, lightweight)
- **Analyst CLI** (rule-based natural language answers)

It corresponds to **Project 2 â€” Theme 5**.

---

# ğŸ€ Project Overview

The system streams NBA play-by-play data through Kafka, ingests it into a vector database, and supports **natural-language queries** over the game using semantic search.

You can ask questions like:

- *â€œWho scored the last points?â€*  
- *â€œWhy was there a foul?â€*  
- *â€œWhat happened during the last possession?â€*

---

# ğŸ§± System Architecture

```

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  NBA CSV Data    â”‚      â”‚ replay_game_kafka.py     â”‚
 â”‚ (downloaded once)â”‚ ---> â”‚  sends events to Kafka   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                  Kafka topic: nba_pbp_raw
                                          â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ ingest_to_chroma.py                                   â”‚
               â”‚ - consumes Kafka stream                               â”‚
               â”‚ - builds text + hashing embeddings                    â”‚
               â”‚ - inserts documents into ChromaDB                     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                        ChromaDB vector storage
                               â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ query_chroma.py      analyst_cli.py    â”‚
             â”‚ - semantic search    - rule-based Q&A  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```

---

# ğŸ“ Folder Structure

```

project/
â”‚
â”œâ”€â”€ download_data.py
â”œâ”€â”€ replay_game_kafka.py
â”œâ”€â”€ ingest_to_chroma.py
â”œâ”€â”€ query_chroma.py
â”œâ”€â”€ analyst_cli.py
â”‚
â”œâ”€â”€ data/                   # downloaded CSV files
â”œâ”€â”€ chroma_db/              # persistent vector storage
â””â”€â”€ README.md

````

---

# âš™ï¸ Installation

### Install Python dependencies:

```bash
pip install pandas chromadb confluent-kafka scikit-learn
````

### Install Kafka (Windows)

Unzip Kafka to:

```
C:\kafka_2.13-3.6.0
```

---

# ğŸš€ Run the Full Demo (Step-by-Step)

Open **six terminal windows** and run the following commands.

---

## ğŸªŸ Window 1 â€” Start Zookeeper

```powershell
cd C:\kafka_2.13-3.6.0
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
```

---

## ğŸªŸ Window 2 â€” Start Kafka Broker

```powershell
cd C:\kafka_2.13-3.6.0
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

---

## ğŸªŸ Window 3 â€” Start ingestion (Kafka â†’ Chroma)

```powershell
cd C:\Users\OS\Desktop\data_stream_processing\project
python ingest_to_chroma.py
```

You should see:

```
Ready. Starting ingestion loop...
```

---

## ğŸªŸ Window 4 â€” Replay the NBA game (Producer â†’ Kafka)

```powershell
cd C:\Users\OS\Desktop\data_stream_processing\project
python replay_game_kafka.py
```

Example output:

```
#1 | Q1 | clock=PT12M00S | score 0-0
-> Jump Ball...
```

Meanwhile, ingestion window shows:

```
Ingested 32 events into Chroma
Ingested 64 events...
```

---

## ğŸªŸ Window 5 â€” Query the vector database

```powershell
cd C:\Users\OS\Desktop\data_stream_processing\project
python query_chroma.py
```

Example queries:

```
who scored the last points?
who made the last three-point shot?
what happened at the beginning of the game?
```

---

## ğŸªŸ Window 6 â€” Run the Analyst CLI (rule-based explanation)

```powershell
cd C:\Users\OS\Desktop\data_stream_processing\project
python analyst_cli.py
```

Example interaction:

```
Question: who scored the last points?

--- Retrieved context ---
1. C. Capela alley-oop DUNK...

--- Analyst answer ---
Based on the most relevant recent play, Capela scored the last points.
```

---

# ğŸ” Example Questions to Try

```
who scored the last points?
who committed the most recent foul?
what happened in the last possession?
who made the last 3pt shot?
summarize the last three plays.
why did the possession change?
```

---

# ğŸŒŸ Features

### âœ” Real-time Kafka streaming

Simulates live game feed event-by-event.

### âœ” Local vector embeddings

Efficient HashingVectorizer (no GPU needed).

### âœ” Searchable play-by-play database

Natural-language queries supported via ChromaDB.

### âœ” Analyst mode

Provides readable English explanations of retrieved events.

### âœ” Fully local, no API required

Runs on any machine.

---

# ğŸ”® Future Extensions

* Real LLM integration (OpenAI, Groq, DeepSeek)
* Web app interface (Streamlit / FastAPI)
* Real-time scoring dashboards
* Player analytics & heatmaps
* Multi-game ingestion and retrieval

---

# ğŸ“Œ Notes

* Designed for educational purposes (Project 2 Theme 5).
* Fully reproducible on Windows.
* All computation runs locally (no cloud services required).

---

# ğŸ‰ End of README

For questions or issues, feel free to open an issue or contact the project author.

```
